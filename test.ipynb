{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Adapted from https://debuggercafe.com/implementing-deep-autoencoder-in-pytorch/\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
    "from PIL import Image\n",
    "from torchvision.utils import save_image\n",
    "import os\n",
    "from scipy.stats import chi2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_signals(shape):\n",
    "    \"\"\"generates a noisy signal of a random freuency\n",
    "    \"\"\"\n",
    "    signal = np.zeros(shape)\n",
    "    row = np.random.randint(0, shape[-1])\n",
    "    signal[row] = 1\n",
    "    return signal\n",
    "\n",
    "def generate_noise_templates(arr, shape):\n",
    "    \"\"\"\n",
    "    returns a normalized noisy version of a given signal\n",
    "    \"\"\"\n",
    "    df = 1\n",
    "    noise_layers = []\n",
    "    for i in range(shape[0]):\n",
    "        noise_layers.append(np.array(chi2.rvs(df, size = shape[0])))\n",
    "    noise = np.stack(noise_layers)/np.amax(np.stack(noise_layers))\n",
    "    noisy_signal = arr+noise\n",
    "    return noisy_signal/np.amax(noisy_signal)\n",
    "\n",
    "def gen_data(shape):\n",
    "    x_data, y_data = [], []\n",
    "    for i in range(100):\n",
    "        signal = generate_signals(shape)\n",
    "        y_data.append(signal)\n",
    "        x_data.append(generate_noise_templates(signal, shape))\n",
    "    return x_data, y_data\n",
    "\n",
    "transform = torchvision.transforms.Compose([\n",
    "    torchvision.transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "def get_device():\n",
    "    if torch.cuda.is_available():\n",
    "        device = 'cuda:0'\n",
    "    else:\n",
    "        device = 'cpu'\n",
    "    return device\n",
    "def make_dir():\n",
    "    image_dir = 'Spectograms'\n",
    "    if not os.path.exists(image_dir):\n",
    "        os.makedirs(image_dir)\n",
    "def save_decoded_image(img, epoch):\n",
    "    img = img.view(*shape)\n",
    "    save_image(img, './Sceptrogram{}.png'.format(epoch))\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        feats = len(np.ravel(x_data[0]))\n",
    "        \n",
    "        self.enc1 = nn.Conv2d(1,5,(5,5), padding = 2)\n",
    "        self.enc2 = nn.Conv2d(5,15,(5,5), padding = 2)\n",
    "        \n",
    "        self.fc1 = nn.Linear(5*5*15, 100)\n",
    "        self.fc2 = nn.Linear(100,20)\n",
    "        self.fc3 = nn.Linear(20,2)\n",
    "#         self.enc2 = nn.Conv2D(1,1,(3,3))\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.enc1(x))\n",
    "        print(x.shape)\n",
    "        x = F.max_pool2d(x, 2,2)\n",
    "        print(x.shape)\n",
    "        x = F.relu(self.enc2(x))\n",
    "        print(x.shape)\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "        print(x.shape)\n",
    "        x = x.view(-1, 5*5*15)\n",
    "        print(x.shape)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        print(x.shape)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        print(x.shape)\n",
    "        x = self.fc3(x)\n",
    "        print(x.shape)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "def test_image_reconstruction(net, testloader):\n",
    "    for image in testloader:\n",
    "        img, _ = image\n",
    "        img = img.to(device)\n",
    "        img = torch.flatten(img)\n",
    "        outputs = net(img)\n",
    "        outputs = outputs.view(*shape)\n",
    "        save_image(outputs, 'spectrogram.png')\n",
    "#         plt.imshow(outputs.cpu())\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_TRAIN torch.Size([10, 20, 20]) Y_TRAIN torch.Size([10, 20, 20])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected 4-dimensional input for 4-dimensional weight [5, 1, 5, 5], but got 3-dimensional input of size [10, 20, 20] instead",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-5a6267071421>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m         \u001b[0mb\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'X_TRAIN'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Y_TRAIN'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#no flattening\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-5-d124ba931dc9>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menc1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_pool2d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 423\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    424\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    425\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[1;34m(self, input, weight)\u001b[0m\n\u001b[0;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m    419\u001b[0m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[1;32m--> 420\u001b[1;33m                         self.padding, self.dilation, self.groups)\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Expected 4-dimensional input for 4-dimensional weight [5, 1, 5, 5], but got 3-dimensional input of size [10, 20, 20] instead"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "model = Autoencoder()\n",
    "\n",
    "#DATA\n",
    "x,y = gen_data((20,20))\n",
    "tensor_x = torch.Tensor(x_data) \n",
    "tensor_y = torch.Tensor(y_data)\n",
    "\n",
    "my_dataset = TensorDataset(tensor_x,tensor_y) \n",
    "trainloader = DataLoader(my_dataset, batch_size = 10, shuffle =True)\n",
    "\n",
    "epochs = 5\n",
    "train_losses, test_losses, train_correct, test_correct = [],[],[],[]\n",
    "\n",
    "for i in range(num_epochs):\n",
    "    \n",
    "    trn_corr, tst_corr = 0,0\n",
    "    \n",
    "    for b, (x_train, y_train) in enumerate(trainloader):\n",
    "        b+=1\n",
    "        print('X_TRAIN',x_train.shape, 'Y_TRAIN',y_train.shape)\n",
    "        y_pred = model(x_train) #no flattening\n",
    "        \n",
    "        loss = criterion(y_pred, y_train)\n",
    "        predicted = torch.max(y_pred,1)[1]\n",
    "        batch_corr = (predicted==y_train).sum()\n",
    "        trn_corr += batch_corr\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if b%100==0:\n",
    "            print(f'EPOCH: {i}, BATCH: {b}, LOSS: {loss.item()}')\n",
    "            \n",
    "    train_loss.append(loss)\n",
    "    train_correct.append(trn_corr)\n",
    "    \n",
    "    #TEST\n",
    "    with torch.no_grad():\n",
    "        for b,(x_test, y_test) in enumerate(trainloader):\n",
    "            y_val = model(x_test)\n",
    "            \n",
    "            predicted = torch.max(y_val.data,1)[1]\n",
    "            tst_corr += (predicted==y_test).sum()\n",
    "            \n",
    "    loss = criterion(y_val, y_test)\n",
    "    test_losses.append(loss)\n",
    "    test_correct.append(tst_corr)\n",
    "        \n",
    "    \n",
    "        \n",
    "        \n",
    "current_time = time.time()\n",
    "total - current_times/start_time\n",
    "print(f'Time passed: {total/60}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE cpu\n",
      "True\n",
      "torch.Size([1, 5, 20, 20])\n",
      "torch.Size([1, 5, 10, 10])\n",
      "torch.Size([1, 15, 10, 10])\n",
      "torch.Size([1, 15, 5, 5])\n",
      "torch.Size([1, 375])\n",
      "torch.Size([1, 100])\n",
      "torch.Size([1, 20])\n",
      "torch.Size([1, 2])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\dom\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\loss.py:446: UserWarning: Using a target size (torch.Size([1, 1, 20, 20])) that is different to the input size (torch.Size([1, 2])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n",
      "  return F.mse_loss(input, target, reduction=self.reduction)\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (2) must match the size of tensor b (20) at non-singleton dimension 3",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-ceaf80ead478>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m \u001b[0mtrain_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainloader\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-4e466c465802>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(net, trainloader, num_epochs)\u001b[0m\n\u001b[0;32m     90\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     91\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 92\u001b[1;33m             \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     93\u001b[0m             \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     94\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 727\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[0;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m    444\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    445\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 446\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mmse_loss\u001b[1;34m(input, target, size_average, reduce, reduction)\u001b[0m\n\u001b[0;32m   2657\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2658\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2659\u001b[1;33m     \u001b[0mexpanded_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_target\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2660\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpanded_input\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexpanded_target\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2661\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\functional.py\u001b[0m in \u001b[0;36mbroadcast_tensors\u001b[1;34m(*tensors)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 71\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_VF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbroadcast_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (2) must match the size of tensor b (20) at non-singleton dimension 3"
     ]
    }
   ],
   "source": [
    "num_epochs = 50\n",
    "learning_rate = 6e-3\n",
    "batch_size = 100\n",
    "\n",
    "shape = (20,20)\n",
    "x_data, y_data = gen_data(shape)\n",
    "\n",
    "# print(x_data[0])\n",
    "tensor_x = torch.Tensor(x_data) \n",
    "tensor_y = torch.Tensor(y_data)\n",
    "\n",
    "my_dataset = TensorDataset(tensor_x,tensor_y) \n",
    "trainloader = DataLoader(my_dataset)\n",
    "# %%\n",
    "\n",
    "\n",
    "device = get_device()\n",
    "device = 'cpu'\n",
    "print('DEVICE', device)\n",
    "print(torch.cuda.is_available())\n",
    "\n",
    "net = Autoencoder()\n",
    "net.to(device)\n",
    "\n",
    "make_dir()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(net.parameters())\n",
    "\n",
    "train_loss = train(net, trainloader, num_epochs)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(train_loss)\n",
    "plt.title('Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "\n",
    "test_image_reconstruction(net, trainloader)\n",
    "# %%\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "optimizer got an empty parameter list",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-a38c960f4049>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mcriterion\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m \u001b[0moptimizer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[0mn_total_steps\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\adam.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, lr, betas, eps, weight_decay, amsgrad)\u001b[0m\n\u001b[0;32m     46\u001b[0m         defaults = dict(lr=lr, betas=betas, eps=eps,\n\u001b[0;32m     47\u001b[0m                         weight_decay=weight_decay, amsgrad=amsgrad)\n\u001b[1;32m---> 48\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAdam\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefaults\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     49\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, params, defaults)\u001b[0m\n\u001b[0;32m     45\u001b[0m         \u001b[0mparam_groups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     46\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 47\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"optimizer got an empty parameter list\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     48\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     49\u001b[0m             \u001b[0mparam_groups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'params'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mparam_groups\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: optimizer got an empty parameter list"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.con1 = nn.Conv2d(1, 2, 5)\n",
    "        self.pool = nn.MaxPool2d(2,2)\n",
    "        self.con2 = nn.Conv2d(2, 4, 5)\n",
    "        self.fc1 = nn.Linear(4*5*5, 80)\n",
    "        self.fc2 = nn.Linear(80,50)\n",
    "        self.fc3 = nn.Linear(50, 2)\n",
    "         \n",
    "    def forward(self,x):\n",
    "        pass\n",
    "    \n",
    "    \n",
    "learning_rate = 1e-3\n",
    "batch_size = 5\n",
    "num_epochs = 50\n",
    "\n",
    "device = get_device()\n",
    "model = CNN().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "n_total_steps = len(trainloader)\n",
    "for epoch in num_epochs:\n",
    "    for i, (image,labels) in enumerate(trainloader):\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if i%5==0:\n",
    "            print('Epoch {} of {}, Train Loss: {:.3f}'.format(\n",
    "            epoch, num_epochs, loss))\n",
    "    print('Training Finished')\n",
    "    \n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x237f881f860>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(np.ravel(gen_noise(shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}